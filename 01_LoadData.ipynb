{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Wetter- und Luftqualitätsdaten\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Woher kommen die Daten und in welcher Form liegen sie vor?\n",
    "\n",
    "#### Wetterdaten Zürich und St. Gallen\n",
    "Die Wetterdaten von Zürich und St. Gallen stammen vom Bundesamt für Meteorologie und Kimatologie - MeteoSchweiz. Abrufbar unter folgendem Link: xxx\n",
    "\n",
    "Es handelt sich hierbei um tägliche Messwerte, die als CSV-Dateien im UFT-8 Format vorliegen. Das Datumsfeld trägt den Namen *reference_timestamp* und ist im Format DD.MM.YYYY HH:MM als Zeichenkette gespeichert. Die Dateien umfassen Messwerte aus zwei Wetterstationen: \n",
    "\n",
    "* Zürich Fluntern (SMA)\n",
    "* St. Gallen (STG)\n",
    "\n",
    "#### Luftqualitätsdaten Zürich und St. Gallen\n",
    "\n",
    "Die Luftqualitätsdaten stammen von der Plattform OSTLUFT abrufbar unter folgendem Link: https://www.ostluft.ch/messwerte/datenabfrage, welche von versch. kantonalen Fachstellen getragen wird, darunter das Amt für Abfall, Wasser, Energie und Luft (AWEL) des Kantons Zürich sowie das Amt für Umwelt des Kantons St. Gallen. \n",
    "\n",
    "Die Daten wurden über die offizielle Datenabfrage-Schnittstelle heruntergeladen und liegen als CSV-Dateien im UFT-8 Format vor. Es handelt sich um aggregierte Tagesmittelwerte wichtiger Parameter für Luftschadstoffe.\n",
    "\n",
    "Das Datumsfeld heisst *Startzeit* udn ist im Format TT.MM.YYYY HH:MM vor. Die Messwerte stammen von zwei festen Luftmessstationen:\n",
    "\n",
    "* **Zürich**: Station Zch_Stampfenbachstr\n",
    "* **St. Gallen**: Station StG_St.Leonhard-Str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Schritt 1: Wetterdaten einlesen\n",
    "\n",
    "# Zürich\n",
    "df_zurich = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .csv(\"data/weather/zurich/ogd-smn_sma_d_historical.csv\")\n",
    "\n",
    "# St. Gallen\n",
    "df_stgallen = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .csv(\"data/weather/stgallen/ogd-smn_stg_d_historical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Zürich\n",
    "df_air_zurich = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .csv(\"data/air_quality/airquality_zurich.csv\") \\\n",
    "    .withColumn(\"location\", lit(\"Zürich\"))\n",
    "\n",
    "# St. Gallen\n",
    "df_air_stgallen = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .csv(\"data/air_quality/airquality_stgallen.csv\") \\\n",
    "    .withColumn(\"location\", lit(\"St. Gallen\"))\n",
    "\n",
    "# Zusammenführen\n",
    "df_air = df_air_zurich.unionByName(df_air_stgallen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Pivotierung der Luftqualitätsdaten\n",
    "\n",
    "Das ursprüngliche Format der Luftqualitätsdaten lag im \"Long Format\" vor. In dieser Struktur entsprach jede Zeile einen einzelnen Messswert, der durch Datum, Standort sowie Schadstoffparameter bestimmt war. Um die Daten jedoch effizient analysieren und mit den Wetterdaten veknüpfen zu könenn, wird eine Pivotierung vorgenommen. Das Ergebnis ist ein \"Wide Format\", bei dem jeder schadstoff als eigene Spalte dargestellt ist. So enthält jede Zeile alle relevanten Messwerte eines Tages für einen bestimmten Standort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col, first, when\n",
    "\n",
    "# Bereinigung\n",
    "df_air_clean = df_air\n",
    "\n",
    "# Pivotierung\n",
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "df_air_clean = df_air_clean.withColumn(\n",
    "    \"date\", to_date(col(\"Startzeit\"), \"dd.MM.yyyy HH:mm\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, first\n",
    "\n",
    "df_luft_pivot = df_air_clean.groupBy(\"date\", \"location\").agg(\n",
    "    first(col(\"PM10\")).alias(\"PM10\"),\n",
    "    first(col(\"`PM2.5`\")).alias(\"PM2.5\"),\n",
    "    first(col(\"Ozon\")).alias(\"Ozon\"),\n",
    "    first(col(\"CO\")).alias(\"CO\"),\n",
    "    first(col(\"NO2\")).alias(\"NO2\"),\n",
    "    first(col(\"NO\")).alias(\"NO\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) Datumsformat vereinheitlichen\n",
    "\n",
    "Um die Verarbeitung sowie Verknüpfung der Wetter- und Luftqualitätsdaten zu ermöglichen, wird das Datumsformat in beiden Datsätzen vereinheitlicht. Die ursprüngliche Datums- und Zeitangabe liegen in unterschiedlcihen Formate vor und zwar:\n",
    "\n",
    "* **Wetterdaten**: DD.MM.YYYY HH:mm (reference_timestamp)\n",
    "* **Luftqualitätsdaten**: DD.MM.YYYY (Startzeit)\n",
    "\n",
    "Durch die Konvertierung in ein einheitliches Datums- und Zeitangabeformat wird sichergestellt, dass beide Quellen korrekt über das Datum gejoint werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "# Wetterdaten: Datum umwandeln\n",
    "df_zurich = df_zurich.withColumn(\n",
    "    \"date\", to_date(col(\"reference_timestamp\"), \"dd.MM.yyyy HH:mm\")\n",
    ")\n",
    "df_stgallen = df_stgallen.withColumn(\n",
    "    \"date\", to_date(col(\"reference_timestamp\"), \"dd.MM.yyyy HH:mm\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4) Standortbezeichnung vereinheitlichen\n",
    "\n",
    "Damit Wetter- und Luftqualitätsdaten korrekt zusammengeführt werden können, ist es notwendig, dass die Bezeichnung der Standorte gleich sind. Aktuell haben die Rohdaten noch unterschiedliche Standortbezeichnungen:\n",
    "\n",
    "* **Standort in Wetterdaten**: In der Spalte *station_abbr* finden sich SMA für Zürich und STG für St. Gallen\n",
    "* **Standort in Luftqualitätsdaten**: In der Spalte *location* finden wir Zch_Stampfenbachstr für Zürich und StG_St.Leonhard-Str für St. Gallen\n",
    "\n",
    "Damit der Join erfolgreich passieren wird, wird eine neue Spalte *location* erstellt, in der die Standorte konsistent mit **\"Zürich\"** und **\"St. Gallen\"** benannt werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Standort Wetterdaten standardisieren\n",
    "if \"station_abbr\" in df_zurich.columns:\n",
    "    df_weather_std = df_zurich.withColumn(\n",
    "        \"location\",\n",
    "        when(col(\"station_abbr\") == \"SMA\", \"Zürich\")\n",
    "        .when(col(\"station_abbr\") == \"STG\", \"St. Gallen\")\n",
    "        .otherwise(\"Andere\")\n",
    "    )\n",
    "else:\n",
    "    print(\"Spalte 'station_abbr' nicht gefunden in df_zurich!\")\n",
    "    df_weather_std = df_zurich\n",
    "\n",
    "# Standort Luftqualitätsdaten standardisieren\n",
    "df_air_std = df_luft_pivot.withColumn(\n",
    "    \"location\",\n",
    "    when(col(\"location\").startswith(\"Zch_\"), \"Zürich\")\n",
    "    .when(col(\"location\").contains(\"St. Gallen\"), \"St. Gallen\")\n",
    "    .otherwise(\"Andere\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5) Join Wetter- und Luftqualitätsdaten\n",
    "\n",
    "Die Zusammenführung der Wetter- und Luftqualitätsdaten brauchen wir, damit wir später mit einem einheitlichen Datensatz weiter arbeiten können, der alle relevanten Merkmale für eine Modellierung beinhaltet. Die Wetter- und Luftqualitätsdaten sind grundsätzlich örtlich und zeitlich aufeinander abgestimtm worden und können nun miteinander verknüpft werden.\n",
    "\n",
    "Ziel ist es mögliche Wettereinflüsse auf die Luftqualität zu analysieren und so ein prädiktives Modell zu trainieren. Durch den Join stehen uns pro Zeile sowohl meterologische als auch umweltrelevante Parameter pro Tag und Standort zur Verfügung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "df_air_std = df_air_std.filter((col(\"date\").isNotNull()) & (year(\"date\") > 1900))\n",
    "df_weather_std = df_weather_std.filter((col(\"date\").isNotNull()) & (year(\"date\") > 1900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_air_std.join(\n",
    "    df_weather_std,\n",
    "    on=[\"date\", \"location\"],\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
