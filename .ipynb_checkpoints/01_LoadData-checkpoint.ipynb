{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/15 17:54:22 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "## Spark Session starten\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Wetter- und Luftqualitätsdaten\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Woher kommen die Daten und in welcher Form liegen sie vor?\n",
    "\n",
    "#### Wetterdaten Zürich und St. Gallen\n",
    "Die Wetterdaten von Zürich und St. Gallen stammen vom Bundesamt für Meteorologie und Kimatologie - MeteoSchweiz. Abrufbar unter folgendem Link: xxx\n",
    "\n",
    "Es handelt sich hierbei um tägliche Messwerte, die als CSV-Dateien im UFT-8 Format vorliegen. Das Datumsfeld trägt den Namen *reference_timestamp* und ist im Format DD.MM.YYYY HH:MM als Zeichenkette gespeichert. Die Dateien umfassen Messwerte aus zwei Wetterstationen: \n",
    "\n",
    "* Zürich Fluntern (SMA)\n",
    "* St. Gallen (STG)\n",
    "\n",
    "#### Luftqualitätsdaten \n",
    "\n",
    "NEU SCHREIBEN\n",
    "\n",
    "\n",
    "https://www.ostluft.ch/messwerte/datenabfrage\n",
    "\n",
    "\n",
    "Die Luftqualitätsdaten stammen vom Amt für Abfall, Wasser, Energie udn Luft (AWEL) des Kantons Zürich sowie dem Amt für Umwelt des Kantons St. Gallen. Abrufbar unter folgendem Link: xxx\n",
    "\n",
    "Es handelt sich um tägliche Mittelwerte der Luftschadstoffe, die als CSV-Dataeien im UFT-8 Format vorliegen. Das Datumsfeld trägt den Namen *Datum* und ist im Format JJJ-MM-TT HH:MM+ZZ+ZZ als Zeichenkette gespeichert. Die Dateien umfassen Messwerte für Zwei Luftmessstationen:\n",
    "\n",
    "* Zürich (Zch_Stampfenbachstr)\n",
    "* st. Gallen (StG_St.Leonhard-Str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Schritt 1: Wetterdaten einlesen\n",
    "\n",
    "# Zürich\n",
    "df_zurich = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .csv(\"data/weather/zurich/ogd-smn_sma_d_historical.csv\")\n",
    "\n",
    "# St. Gallen\n",
    "df_stgallen = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .csv(\"data/weather/stgallen/ogd-smn_stg_d_historical.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Pivotierung der Luftqualitätsdaten\n",
    "\n",
    "Das ursprüngliche Format der Luftqualitätsdaten lag im \"Long Format\" vor. In dieser Struktur entsprach jede Zeile einen einzelnen Messswert, der durch Datum, Standort sowie Schadstoffparameter bestimmt war. Um die Daten jedoch effizient analysieren und mit den Wetterdaten veknüpfen zu könenn, wird eine Pivotierung vorgenommen. Das Ergebnis ist ein \"Wide Format\", bei dem jeder schadstoff als eigene Spalte dargestellt ist. So enthält jede Zeile alle relevanten Messwerte eines Tages für einen bestimmten Standort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col, first, when\n",
    "\n",
    "# Bereinigung\n",
    "df_air_clean = df_air\n",
    "\n",
    "# Pivotierung\n",
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "df_air_clean = df_air_clean.withColumn(\n",
    "    \"date\", to_date(col(\"Startzeit\"), \"dd.MM.yyyy HH:mm\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import first\n",
    "\n",
    "df_luft_pivot = df_air.groupBy(\"Startzeit\", \"location\") \\\n",
    "    .agg(\n",
    "        first(\"PM10\").alias(\"PM10\"),\n",
    "        first(\"PM2.5\").alias(\"PM2.5\"),\n",
    "        first(\"Ozon\").alias(\"Ozon\"),\n",
    "        first(\"CO\").alias(\"CO\"),\n",
    "        first(\"NO2\").alias(\"NO2\"),\n",
    "        first(\"NO\").alias(\"NO\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import first, col\n",
    "\n",
    "df_luft_pivot = df_air.groupBy(\"Startzeit\", \"location\") \\\n",
    "    .agg(\n",
    "        first(col(\"PM10\")).alias(\"PM10\"),\n",
    "        first(col(\"`PM2.5`\")).alias(\"PM2.5\"),\n",
    "        first(col(\"Ozon\")).alias(\"Ozon\"),\n",
    "        first(col(\"CO\")).alias(\"CO\"),\n",
    "        first(col(\"NO2\")).alias(\"NO2\"),\n",
    "        first(col(\"NO\")).alias(\"NO\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) Datumsformat vereinheitlichen\n",
    "\n",
    "Um die Verarbeitung sowie Verknüpfung der Wetter- und Luftqualitätsdaten zu ermöglichen, wird das Datumsformat in beiden Datsätzen vereinheitlicht. Die ursprüngliche Datums- und Zeitangabe liegen in unterschiedlcihen Formate vor und zwar:\n",
    "\n",
    "* **Wetterdaten**: DD.MM.YYYY HH:mm (reference_timestamp)\n",
    "* **Luftqualitätsdaten**: DD.MM.YYYY (Startzeit)\n",
    "\n",
    "Durch die Konvertierung in ein einheitliches Datums- und Zeitangabeformat wird sichergestellt, dass beide Quellen korrekt über das Datum gejoint werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "# Wetterdaten: Datum umwandeln\n",
    "df_zurich = df_zurich.withColumn(\n",
    "    \"date\", to_date(col(\"reference_timestamp\"), \"dd.MM.yyyy HH:mm\")\n",
    ")\n",
    "df_stgallen = df_stgallen.withColumn(\n",
    "    \"date\", to_date(col(\"reference_timestamp\"), \"dd.MM.yyyy HH:mm\")\n",
    ")\n",
    "\n",
    "# Luftqualitätsdaten: Datum umwandeln\n",
    "df_luft_pivot = df_luft_pivot.withColumn(\n",
    "    \"date\", to_date(col(\"Startzeit\"), \"dd.MM.yyyy HH:mm\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4) Standortbezeichnung vereinheitlichen\n",
    "\n",
    "Um die Wetter- und Luftqualitätsdaten sinnvoll miteinander verknüpfen zu können, muss die Bezeichnung der jeweiligen Standorte gleich sein. In den vorhanden Dateien jedoch gibt es unterschiedliche Bezeichnungen der Standorte, was ein Join erschwert. Beispielsweise steht in den Wetterdaten *SMA* für Zürich und in den Luftqualitätsdaten finden wir *Zch_...* für Zürich. \n",
    "\n",
    "Diese ungleiche Benennung würde einen Join der beiden Datensätze nicht ermöglichen. Somit wird die Standortbezeichnung vereinheitlicht, so dass wir sichergestellen können, dass die Werte für Zürich und St. Gallen korrekt zusammengeführt werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Standort Wetterdaten standardisieren\n",
    "if \"station_abbr\" in df_zurich.columns:\n",
    "    df_weather_std = df_zurich.withColumn(\n",
    "        \"location\",\n",
    "        when(col(\"station_abbr\") == \"SMA\", \"Zürich\")\n",
    "        .when(col(\"station_abbr\") == \"STG\", \"St. Gallen\")\n",
    "        .otherwise(\"Andere\")\n",
    "    )\n",
    "else:\n",
    "    print(\"Spalte 'station_abbr' nicht gefunden in df_zurich!\")\n",
    "    df_weather_std = df_zurich\n",
    "\n",
    "# Standort Luftqualitätsdaten standardisieren\n",
    "df_air_std = df_luft_pivot.withColumn(\n",
    "    \"location\",\n",
    "    when(col(\"location\").startswith(\"Zch_\"), \"Zürich\")\n",
    "    .when(col(\"location\").contains(\"St. Gallen\"), \"St. Gallen\")\n",
    "    .otherwise(\"Andere\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5) Wetter- und Luftqualitätsdaten anschauen bevor sie gejoint werden\n",
    "\n",
    "Bevor die bereinigten und standardisierten Wetter- und Luftqualitätsdaten auf Tagesbasis zusammengeführt werden, erfolgt eine vorläufige Analyse. Ziel ist es, sicherzustellen, dass der Join reibungslos funktioniert und keine Inkonsistenzen in den Datums- oder Standortangaben bestehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5) Join Wetter- und Luftqualitätsdaten\n",
    "\n",
    "Die Zusammenführung der Wetter- und Luftqualitätsdaten brauchen wir, damit wir später mit einem einheitlichen Datensatz weiter arbeiten können, der alle relevanten Merkmale für eine Modellierung beinhaltet. Die Wetter- und Luftqualitätsdaten sind grundsätzlich örtlich und zeitlich aufeinander abgestimtm worden und können nun miteinander verknüpft werden.\n",
    "\n",
    "Ziel ist es mögliche Wettereinflüsse auf die Luftqualität zu analysieren und so ein prädiktives Modell zu trainieren. Durch den Join stehen uns pro Zeile sowohl meterologische als auch umweltrelevante Parameter pro Tag und Standort zur Verfügung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_air_std.join(\n",
    "    df_weather_std,\n",
    "    on=[\"date\", \"location\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Anzahl Zeilen und Vorschau auf kombinierte Einträge\n",
    "print(\"Anzahl Zeilen nach dem Join\", df_joined.count())\n",
    "df_joined.select(\"date\", \"location\").distinct().show(5)\n",
    "\n",
    "# Optional: Schema und erste Einträge anzeigen\n",
    "df_joined.printSchema()\n",
    "df_joined.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6) Deskriptive Analyse Wetter- und Luftqualitätsdaten nach dem Join\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Zeilen Wetterdaten: 58805\n",
      "Anzahl Zeilen Luftqualitätsdaten: 7308\n"
     ]
    }
   ],
   "source": [
    "## Schritt 1: Anzahl Zeilen in DataFrames vor und nach Join\n",
    "\n",
    "print(\"Anzahl Zeilen Wetterdaten:\", df_zurich.count())\n",
    "print(\"Anzahl Zeilen Luftqualitätsdaten:\", df_luft_pivot.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Schritt 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalten in df_luft_pivot:\n",
      "['Datum', 'Standort', 'CO', 'NO', 'NO2', 'NOx', 'O3', 'O3_max_h1', 'O3_nb_h1>120', 'PM10', 'PM2.5', 'PN', 'SO2', 'date']\n",
      "\n",
      "Spalten in df_zurich:\n",
      "['station_abbr', 'reference_timestamp', 'tre200d0', 'tre200dx', 'tre200dn', 'tre005d0', 'tre005dx', 'tre005dn', 'ure200d0', 'pva200d0', 'prestad0', 'pp0qffd0', 'ppz850d0', 'ppz700d0', 'pp0qnhd0', 'fkl010d0', 'fkl010d1', 'fu3010d0', 'fu3010d1', 'fkl010d3', 'fu3010d3', 'wcc006d0', 'rre150d0', 'rka150d0', 'htoautd0', 'gre000d0', 'oli000d0', 'olo000d0', 'osr000d0', 'ods000d0', 'sre000d0', 'sremaxdv', 'erefaod0', 'xcd000d0', 'dkl010d0', 'xno000d0', 'xno012d0', 'rreetsd0', 'date']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
